{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# Chapter 2: Bayesian Data Analysis\n\n**From Statistical Rethinking by Richard McElreath**\n\nThese notes faithfully follow your handwritten notes structure:\n- Probability as degree of plausibility (Laplace\u2013Jeffreys\u2013Cox\u2013Jaynes)\n- Competing conjectures\n- Joint distributions and marginalisation\n- Two views of likelihood\n- Predictive distributions\n- Panda Problem with genetic test (sequential updating)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy import stats\n\nnp.random.seed(42)\nrng = np.random.default_rng(42)\n\nplt.style.use('default')\n%matplotlib inline\n\nprint('\u2713 Imports loaded')"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 1. Probability and Uncertainty\n\nProbability represents **uncertainty in parameters**, arising from:\n- Measurement errors\n- Imperfections in the model\n\n### Multiple Competing Conjectures\n\n- Multiple conjectures (hypotheses) considered **simultaneously**\n- All compete at the same time\n\n> **Key principle:** A conjecture that produces the data in more ways is more probable\n\n### Interpretation of Probability\n\n**NOT long-run frequency!**\n\nFollows the **Laplace\u2013Jeffreys\u2013Cox\u2013Jaynes** interpretation:\n\n> **Probability = Degree of plausibility**\n\nThis means parameters can have probability distributions (Bayesian view)."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 2. Core Bayesian Concepts\n\n### Parameter\nEvery discrete value of a parameter is a **conjecture**.\n\n### Likelihood P(D | \u03b8)\n- **Relative number of ways** a parameter value can produce the data\n- Measures how **compatible** the data is with a conjecture\n\n$$P(D \\mid \\theta)$$\n\n### Prior P(\u03b8)\n- Prior possibilities of all parameter values\n- Encodes plausibility **before seeing data**\n\n$$P(\\theta)$$\n\n### Posterior P(\u03b8 | D)\n- Updated probability of parameter values\n- After conditioning on observed data\n\n$$P(\\theta \\mid D)$$"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Visualize the four core concepts\ntheta_values = np.linspace(0, 1, 100)\nn_heads, n_tosses = 7, 10\n\n# Prior: Uniform\nprior = np.ones_like(theta_values)\nprior = prior / np.trapezoid(prior, theta_values)\n\n# Likelihood\nlikelihood = stats.binom.pmf(n_heads, n_tosses, theta_values)\n\n# Posterior\nposterior = prior * likelihood\nposterior = posterior / np.trapezoid(posterior, theta_values)\n\n# Plot\nfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n\naxes[0, 0].plot(theta_values, prior, 'b-', linewidth=2.5)\naxes[0, 0].fill_between(theta_values, prior, alpha=0.3)\naxes[0, 0].set_title('Prior P(\u03b8)', fontsize=13, fontweight='bold')\naxes[0, 0].set_xlabel('\u03b8')\naxes[0, 0].set_ylabel('Density')\naxes[0, 0].grid(True, alpha=0.3)\n\naxes[0, 1].plot(theta_values, likelihood, 'g-', linewidth=2.5)\naxes[0, 1].fill_between(theta_values, likelihood, alpha=0.3, color='g')\naxes[0, 1].set_title('Likelihood P(D|\u03b8)', fontsize=13, fontweight='bold')\naxes[0, 1].set_xlabel('\u03b8')\naxes[0, 1].set_ylabel('Likelihood')\naxes[0, 1].grid(True, alpha=0.3)\n\naxes[1, 0].plot(theta_values, posterior, 'r-', linewidth=2.5)\naxes[1, 0].fill_between(theta_values, posterior, alpha=0.3, color='r')\naxes[1, 0].set_title('Posterior P(\u03b8|D)', fontsize=13, fontweight='bold')\naxes[1, 0].set_xlabel('\u03b8')\naxes[1, 0].set_ylabel('Density')\naxes[1, 0].grid(True, alpha=0.3)\n\naxes[1, 1].axis('off')\naxes[1, 1].text(0.1, 0.5, f'''Example: 7 heads / 10 tosses\n\nPrior: Uniform (all \u03b8 equally plausible)\nLikelihood: Binomial(7|10,\u03b8)\nPosterior: Updated beliefs after data\n\nPeak at \u03b8 \u2248 0.7\n''', fontsize=11, family='monospace', verticalalignment='center')\n\nplt.tight_layout()\nplt.show()"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 3. Discrete Parameter Case\n\nLet: $$\\theta \\in \\{\\theta_1, \\theta_2, \\dots, \\theta_n\\}$$\n\nPosterior:\n$$P(\\theta_i \\mid y) = \\frac{P(y \\mid \\theta_i) P(\\theta_i)}{P(y)}$$\n\nWhere:\n$$P(y) = \\sum_i P(y \\mid \\theta_i) P(\\theta_i)$$\n\n### Interpretation of Denominator\n\nThe denominator P(y) has three equivalent interpretations:\n1. **Average likelihood over the prior**\n2. **Expected likelihood**\n3. **Marginalisation over \u03b8**\n\nThis ensures probabilities sum to 1."
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 4. Likelihood as a Generative Object\n\nBayesian models are **generative**.\n\n### Two Views of Likelihood\n\n**View 1: Data \u2192 Parameter (Inference)**\n- Given data, how compatible is each parameter?\n- Used in posterior computation\n\n**View 2: Parameter \u2192 Data (Prediction)**\n- Given parameter, probability of observing data\n- Used in prediction\n\n> **Key insight:** Prediction = averaging likelihood over parameter distribution"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 5. Continuous Parameters\n\nFor continuous parameters:\n\n$$P(\\theta \\mid y) = \\frac{P(y \\mid \\theta) P(\\theta)}{\\int P(y \\mid \\theta) P(\\theta) \\, d\\theta}$$\n\n- Integral replaces summation\n- Still marginalisation over \u03b8\n\n### Joint Distribution\n\nThe joint distribution contains **complete information**.\n\nFrom joint P(y,\u03b8) = P(y|\u03b8)P(\u03b8), we obtain:\n- Marginal distributions\n- Predictive distributions"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n## 6. Predictive Distributions\n\n### Prior Predictive\nBefore observing data:\n\n$$P(y) = \\int P(y \\mid \\theta) P(\\theta) \\, d\\theta$$\n\n(average likelihood over prior)\n\n### Posterior Predictive\nAfter observing data:\n\n$$P(y_{new} \\mid y) = \\int P(y_{new} \\mid \\theta) P(\\theta \\mid y) \\, d\\theta$$\n\n(average likelihood over posterior)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "---\n\n# Worked Example: The Panda Problem\n\nNow we apply everything to the complete panda problem with **genetic test**!\n\n## Problem Statement\n\n- Two panda species: **A** and **B**\n- Both equally common\n- Twin birth rates:\n  - $P(T \\mid S_A) = 0.1$\n  - $P(T \\mid S_B) = 0.2$\n- Genetic test:\n  - $P(A^+ \\mid S_A) = 0.8$ (true positive)\n  - $P(A^+ \\mid S_B) = 0.35$ (false positive)\n\n**Observations (sequential):**\n1. Panda gives birth to twins\n2. Genetic test positive for Species A\n\n**Questions:**\n- What is P(Species) after each observation?\n- What is P(next birth = twins)?"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 1: Prior\n\n$$P(S_A) = 0.5, \\quad P(S_B) = 0.5$$"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "print(\"=\"*70)\nprint(\"PANDA PROBLEM: Sequential Bayesian Updating\")\nprint(\"=\"*70)\n\n# Step 1: Prior\np_A = 0.5\np_B = 0.5\n\nprint(\"\\nSTEP 1: PRIOR\")\nprint(f\"P(Species A) = {p_A}\")\nprint(f\"P(Species B) = {p_B}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 2: Posterior After Twin Birth\n\n$$P(S_A \\mid T) = \\frac{0.1 \\times 0.5}{0.1 \\times 0.5 + 0.2 \\times 0.5} = 0.333$$\n\n$$P(S_B \\mid T) = 0.667$$\n\n**Intuition:** Twin birth favors Species B!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 2: Update after twins\np_twins_given_A = 0.1\np_twins_given_B = 0.2\n\np_twins = p_twins_given_A * p_A + p_twins_given_B * p_B\np_A_after_twins = (p_twins_given_A * p_A) / p_twins\np_B_after_twins = (p_twins_given_B * p_B) / p_twins\n\nprint(\"\\nSTEP 2: AFTER TWIN BIRTH\")\nprint(f\"P(Species A | Twins) = {p_A_after_twins:.3f}\")\nprint(f\"P(Species B | Twins) = {p_B_after_twins:.3f}\")\nprint(f\"Species B is {p_B_after_twins/p_A_after_twins:.1f}\u00d7 more likely!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 3: Posterior Predictive After Twin Birth\n\n$$P(T_{next}) = 0.1 \\times 0.333 + 0.2 \\times 0.667 = 0.167$$\n\nPrior predictive was 0.150, so twins increased!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 3: Posterior predictive\np_twins_prior_pred = 0.1 * 0.5 + 0.2 * 0.5\np_twins_post_pred = 0.1 * p_A_after_twins + 0.2 * p_B_after_twins\n\nprint(\"\\nSTEP 3: POSTERIOR PREDICTIVE\")\nprint(f\"Prior predictive:     {p_twins_prior_pred:.3f}\")\nprint(f\"After twins:          {p_twins_post_pred:.3f}\")\nprint(f\"Change: +{100*(p_twins_post_pred-p_twins_prior_pred)/p_twins_prior_pred:.1f}%\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 4: Genetic Test Evidence\n\nTest characteristics:\n- $P(A^+ \\mid S_A) = 0.8$\n- $P(A^+ \\mid S_B) = 0.35$\n\n**Key:** Posterior from Step 2 becomes new prior!\n$$P(S_A) = 0.333, \\quad P(S_B) = 0.667$$\n\nThis is **sequential updating**!"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 5: Posterior After Genetic Test\n\n$$P(S_A \\mid A^+) = \\frac{0.8 \\times 0.333}{0.8 \\times 0.333 + 0.35 \\times 0.667} = 0.533$$\n\n$$P(S_B \\mid A^+) = 0.467$$\n\n**Intuition:** Test shifts beliefs back toward A!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 5: Update after genetic test\np_test_A_given_A = 0.8\np_test_A_given_B = 0.35\n\np_test_A = p_test_A_given_A * p_A_after_twins + p_test_A_given_B * p_B_after_twins\np_A_final = (p_test_A_given_A * p_A_after_twins) / p_test_A\np_B_final = (p_test_A_given_B * p_B_after_twins) / p_test_A\n\nprint(\"\\nSTEP 5: AFTER GENETIC TEST\")\nprint(f\"P(Species A | Test A+) = {p_A_final:.3f}\")\nprint(f\"P(Species B | Test A+) = {p_B_final:.3f}\")\nprint(f\"\\nShift: A went {p_A_after_twins:.3f} \u2192 {p_A_final:.3f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Step 6: Updated Posterior Predictive\n\n$$P(T_{next}) = 0.533 \\times 0.1 + 0.467 \\times 0.2 = 0.147$$\n\nEvolution: 0.15 \u2192 0.167 \u2192 0.147"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Step 6: Final posterior predictive\np_twins_final_pred = 0.1 * p_A_final + 0.2 * p_B_final\n\nprint(\"\\nSTEP 6: FINAL POSTERIOR PREDICTIVE\")\nprint(f\"Prior predictive:     {p_twins_prior_pred:.3f}\")\nprint(f\"After twins:          {p_twins_post_pred:.3f}\")\nprint(f\"After test:           {p_twins_final_pred:.3f}\")\nprint(\"\\nData pushed predictions up, then back down!\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "## Final Summary\n\n### Parameter Evolution\n- $S_A$: 0.5 \u2192 0.33 \u2192 0.533\n- $S_B$: 0.5 \u2192 0.67 \u2192 0.467\n\n### Prediction Evolution\n$$P(T_{next}): 0.15 \\rightarrow 0.167 \\rightarrow 0.147$$\n\n### Core Takeaway\n> Evidence updates parameter plausibility.  \n> Updated parameters update predictions.  \n> This is sequential Bayesian learning!"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Final visualization\nstages = ['Prior', 'After\\nTwins', 'After\\nTest']\np_A_evolution = [0.5, p_A_after_twins, p_A_final]\np_B_evolution = [0.5, p_B_after_twins, p_B_final]\n\nfig, ax = plt.subplots(figsize=(12, 6))\nx = np.arange(len(stages))\nwidth = 0.35\n\nax.bar(x - width/2, p_A_evolution, width, label='Species A', \n       color='#1f77b4', edgecolor='black', linewidth=2, alpha=0.8)\nax.bar(x + width/2, p_B_evolution, width, label='Species B',\n       color='#ff7f0e', edgecolor='black', linewidth=2, alpha=0.8)\n\nax.set_ylabel('Probability', fontsize=13)\nax.set_title('Sequential Bayesian Updating: The Panda Problem', \n             fontsize=15, fontweight='bold')\nax.set_xticks(x)\nax.set_xticklabels(stages, fontsize=11)\nax.legend(fontsize=12)\nax.set_ylim(0, 0.8)\nax.grid(True, alpha=0.3, axis='y')\n\nfor i, (va, vb) in enumerate(zip(p_A_evolution, p_B_evolution)):\n    ax.text(i - width/2, va + 0.02, f'{va:.3f}', \n            ha='center', fontsize=10, fontweight='bold')\n    ax.text(i + width/2, vb + 0.02, f'{vb:.3f}', \n            ha='center', fontsize=10, fontweight='bold')\n\nplt.tight_layout()\nplt.show()\n\nprint(\"=\"*70)\nprint(\"COMPLETE! This is Bayesian inference in action.\")\nprint(\"=\"*70)"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}